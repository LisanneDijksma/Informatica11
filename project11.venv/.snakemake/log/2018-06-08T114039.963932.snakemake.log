Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	final
	1	get_all_ids
	1	get_genes
	1	get_pubmed_ids
	1	get_some_ids
	5

rule get_some_ids:
    input: ../Blok11/data/RNA-Seq-counts.txt
    output: ID.csv
    jobid: 2

Finished job 2.
1 of 5 steps (20%) done

rule get_all_ids:
    input: ../Blok11/data/RNA-Seq-counts.txt
    output: groot_ID.csv
    jobid: 3

Finished job 3.
2 of 5 steps (40%) done

rule get_genes:
    input: ID.csv
    output: sequences.fasta
    jobid: 1

Finished job 1.
3 of 5 steps (60%) done

rule get_pubmed_ids:
    input: groot_ID.csv
    output: pubmedids.csv
    jobid: 4

Finished job 4.
4 of 5 steps (80%) done

localrule final:
    input: ID.csv, groot_ID.csv, sequences.fasta, pubmedids.csv
    jobid: 0

Finished job 0.
5 of 5 steps (100%) done
Complete log: /home/lisanne/project11.venv/.snakemake/log/2018-06-08T114039.963932.snakemake.log
